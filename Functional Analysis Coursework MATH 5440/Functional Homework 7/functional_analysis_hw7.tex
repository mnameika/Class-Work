\documentclass{article}
\usepackage{graphicx, mathtools, amsmath, amssymb, float, fancyhdr, halloweenmath}


\setlength{\oddsidemargin}{0in}
\setlength{\textwidth}{6.5in}
\setlength{\topmargin}{-.55in}
\setlength{\textheight}{9in}
\pagestyle{fancy}
\fancyfoot{}
\fancyhead[L]{$\mathbat$ MATH 5350 $\mathbat$}
\fancyhead[R]{$\mathbat$ \thepage \hspace{0.065cm} $\mathbat$}


\begin{document}

\begin{center}
    {\Huge Homework VII}
    \vspace{0.5cm}
    
    {\Large Michael Nameika}
\end{center}


\section*{Section 3.4 Problems}
\begin{itemize}
    \item[\textbf{8}.] Show that an element $x$ of an inner product space $X$ cannot have ``too many" Fourier coefficients $\langle x, e_k \rangle$ which are ``big"; here $(e_k)$ is a given orthonormal sequence; more precisely, show that the number $n_m$ of $\langle x, e_k\rangle$ such that $|\langle x, e_k \rangle| > 1/m$ must satisfy $n_m < m^2 \|x\|^2$.
    \newline\newline
    \textit{Proof:} Let $\{e_l\}$ be the subset of elements of $\{e_k\}$ such that $|\langle x, e_k \rangle| > 1/m$. Suppose that there are $n_m$ of such elements. We will show that $n_m < \infty$. Notice, by Bessel's inequality,
    \begin{align*}
        \sum_{l = 1}^{n_m} |\langle x, e_l \rangle|^2 &\leq \|x\|^2
    \end{align*}
    and that, since $\langle x, e_l \rangle > 1/m$, we have
    \begin{align*}
        \frac{n_m}{m^2} < \sum_{l = 1}^{n_m} |\langle x, e_l \rangle |^2.
    \end{align*}
    Using this inequality along with Bessel's inequality above, we have
    \begin{align*}
        \frac{n_m}{m^2} < \|x\|^2\\
        n_m < m^2\|x\|^2
    \end{align*}
    so that $n_m$ is bounded and hence finite. \hfill $\mathghost$

    \item[\textbf{9}.] Orthonormalize the first three terms of the sequence $(x_0, x_1, x_2, \cdots)$, where $x_j(t) = t^j$, on the interval $[-1, 1]$, where
    \[\langle x, y\rangle = \int_{-1}^1 x(t)y(t)dt.\]
    \textit{Soln.} Applying the Gram-Schmidt process, let $v_0 = x_0 = 1$. Then taking $e_0 = \frac{v_0}{\|v_0\|}$, we have
    \begin{align*}
        \|v_0\| &= \sqrt{\int_{-1}^1 dt}\\
        &= \sqrt{2}
    \end{align*}
    so that $e_1 = \frac{1}{\sqrt{2}}$. Now, $v_1 = x_1 - \langle x_1, e_0\rangle e_0$ for $x_1 = t$. Then
    \begin{align*}
        \langle x_1, e_0\rangle &= \int_{-1}^1 \frac{1}{\sqrt{2}}tdt\\
        &= 0
    \end{align*}
    and so $v_1 = x_1 = t$. Normalizing,
    \begin{align*}
        \|v_1\| &= \sqrt{\int_{-1}^1 t^2dt}\\
        &= \sqrt{\frac{2}{3}}
    \end{align*}
    so that
    \[e_1 = \frac{v_1}{\|v_1\|} = \sqrt{\frac{3}{2}} t.\]
    Finally, finding $v_2 = x_2 - \langle x_2, e_1\rangle e_1 - \langle x_2, e_0\rangle e_0$:
    \begin{align*}
        \langle x_2, e_1\rangle &= \int_{-1}^{1} \sqrt{\frac{3}{2}}t (t^2)dt\\
        &= \sqrt{\frac{3}{2}}\int_{-1}^1 t^3 dt\\
        &= 0
    \end{align*}
    and
    \begin{align*}
        \langle x_2, e_0 \rangle e_0 &= \left(\int_{-1}^1 \frac{1}{\sqrt{2}} t^2dt \right)e_0\\
        &= \frac{1}{\sqrt{2}}\frac{2}{3}e_0\\
        &= \frac{\sqrt{2}}{3}\left(\frac{1}{\sqrt{2}}\right)\\
        &= \frac{1}{3}.
    \end{align*}
    We now have
    \[v_2 = t^2 - \frac{1}{3}.\]
    Normalizing,
    \begin{align*}
        \|v_2\| &= \sqrt{\int_{-1}^1\left(t^2 - \frac{1}{3}\right)^2dt}\\
        &= \sqrt{\int_{-1}^1\left(t^4 - \frac{2}{3}t^2 + \frac{1}{9}\right)dt}\\
        &= \sqrt{\frac{2}{5} - \frac{4}{9} + \frac{2}{9}}\\
        &= \sqrt{\frac{2}{5} - \frac{2}{9}}\\
        &= \sqrt{\frac{8}{45}}\\
        &= \frac{2\sqrt{2}}{3\sqrt{5}}
    \end{align*}
    so that
    \begin{align*}
        e_2 &= \frac{3\sqrt{5}}{2\sqrt{2}}\left(t^2 - \frac{1}{3}\right)\\
        &= \frac{3\sqrt{5}}{2\sqrt{2}}t^2 - \frac{\sqrt{5}}{2\sqrt{2}}.
    \end{align*}
    Then the first few orthonormal terms are 
    \[\{e_0,e_1,e_2\} = \left\{\frac{1}{\sqrt{2}}, \hspace{0.5em} \sqrt{\frac{3}{2}}t, \hspace{0.5em} \frac{3\sqrt{5}}{2\sqrt{2}}t^2 - \frac{\sqrt{5}}{2\sqrt{2}}\right\}\]
    \hfill $\mathghost$
\end{itemize}


\section*{Section 3.5 Problems}
\begin{itemize}
    \item[\textbf{6}.] Let $(e_j)$ be an orthonormal sequence in a Hilbert space $H$. Show that if
    \[x = \sum_{j = 1}^{\infty} \alpha_je_j, \hspace{0.6cm} y = \sum_{j = 1}^{\infty} \beta_je_j, \hspace{0.8cm} \text{then} \hspace{0.8cm} \langle x, y \rangle = \sum_{j = 1}^{\infty} \alpha_j\overline{\beta}_j,\]
    the series being absolutely convergent.
    \newline\newline
    \textit{Proof:} First notice
    \begin{align*}
        \langle x, y \rangle &= \left\langle \sum_{j = 1}^{\infty} \alpha_je_j, \sum_{k = 1}^{\infty}\beta_je_j \right\rangle\\
        &= \sum_{j=1}^{\infty}\sum_{k = 1}^{\infty} \alpha_j\overline{\beta}_k \langle e_j, e_k \rangle\\
        &= \sum_{j=1}^{\infty}\sum_{k=1}^{\infty}\alpha_j\overline{\beta}_k \delta_{jk}\\
        &= \sum_{j = 1}^{\infty} \alpha_j\overline{\beta}_j
    \end{align*}
    where $\delta_{jk}$ is the Kronecker delta. Now, the norm of $x$ and $y$ are given by the following (since $(e_j)$ is orthonormal):
    \begin{align*}
        \|x\|^2 &= \sum_{j = 1}^{\infty} |\alpha_j|^2\\
        \|y\|^2 &= \sum_{j = 1}^{\infty} |\beta_j|^2
    \end{align*}
    each of which is convergent. Then notice
    \begin{align*}
        \left|\sum_{j=1}^{\infty}\alpha_j\overline{\beta_j}\right| &\leq \sum_{j = 1}^{\infty} |\alpha_j\beta_j|^2\\
        &\leq \sum_{j=1}^{\infty}|\alpha_j|^2\sum_{k=1}^{\infty}|\beta_k|^2\\
        &= \|x\|^2\|y\|^2
    \end{align*}
    so that the series is absolutely convergent. \hfill $\mathghost$


    \item[\textbf{8}.] Let $(e_k)$ be an orthonormal sequence in a Hilbert space $H$, and let $M = \text{span}(e_k)$. Show that for any $x \in H$ we have $x \in \overline{M}$ if and only if $x$ can be represented by (6) with coefficients $\alpha_k = \langle x, e_k \rangle$.
    \newline\newline
    \textit{Proof:} First suppose that $x \in H$ can be represented by
    \[\sum_{k = 1}^{\infty}\langle x, e_k \rangle e_k.\]
    Then we have that the sequence $(s_n)$ defined by
    \[\sum_{k = 1}^n \langle x, e_k \rangle e_k\]
    is a Cauchy sequence in $M$ which converges to $x$. Hence $x$ is a limit point of $M$ and so $x \in \overline{M}$.
    \newline
    Now suppose $x \in \overline{M}$. We wish to show that $x$ can be represented by
    \[x = \sum_{k = 1}^{\infty} \langle x, e_k \rangle e_k.\]
    
\end{itemize}


\section*{Section 3.6 Problems}
\begin{itemize}
    \item[\textbf{10}.] Let $M$ be a subset of a Hilbert space $H$, and let $v, w \in H$. Suppose that $\langle v, x\rangle = \langle w, x \rangle$ for all $x \in M$ implies $v = w$. If this holds for all $v, w \in H$, show that $M$ is total in $H$.
    \newline\newline
    \textit{Proof:} To begin, note that for any $x \in H$, $\langle 0, x\rangle = 0$. Now let $v \in M^{\perp}$. That is,
    \[\langle v,x\rangle = 0\]
    for all $x\in M$. Thus,
    \begin{align*}
        \langle v,x \rangle &= \langle 0, x \rangle\\
        \implies v &= 0
    \end{align*}
    Thus, $M^{\perp} = \{0\}$, so that the span of $M$ is dense in $H$, and thus, $M$ is total in $H$.    
\end{itemize}

\section*{Extra Credit Exercise VII.1}
\begin{itemize}
    \item[(a)] Let $(x_j)$ be an \textit{orthogonal} sequence in an inner product space $X$, meaning $\langle x_i, x_j \rangle = 0$ for all $i \neq j$, and suppose that the series $\|x_1\|^2 + \|x_2\|^2 + \|x_3\|^2 + \cdots$ converges. Show that $(s_n)$ is a Cauchy sequence, where $s_n = x_1 + \cdots + x_n$.
    \newline\newline
    \textit{Proof:} Let $(x_j)$ be an orthogonal sequence in an inner product space $X$ and suppose $M = \|x_1\|^2 + \|x_2\|^2 + \cdots$ converges. We will show that $(s_n)$ is a Cauchy sequence. To begin, note that since $M$ converges, the sequence of partial sums $(M_n)$ of $M$ is Cauchy. Fix $\varepsilon > 0$. Then there exists an index $N$ such that for all $n > m > N$, 
    \[\sum_{j = m+1}^n \|x_j\|^2 < \varepsilon^2.\]
    Now let us inspect $\|s_n - s_m\|^2$:
    \begin{align*}
        \|s_n - s_m\|^2 &= \left\langle \sum_{j = m + 1}^n x_j, \sum_{k = m+1}^n x_k \right\rangle\\
        &= \sum_{j = m+1}^n\sum_{k = m+1}^n \langle x_j, x_k\rangle\\
        &= \sum_{j = m+1}^n \|x_j\|^2
    \end{align*}
    since $(x_j)$ is orthogonal. Then
    \begin{align*}
        \|s_n - s_m\|^2 &= \sum_{j = m+1}^n \|x_j\|^2\\
        &< \varepsilon^2\\
        \implies \|s_n - s_m\| &< \varepsilon.
    \end{align*}
    Hence, $(s_n)$ is a Cauchy sequence, as desired.

    \item[(b)] Remove the orthogonality assumption from part (a), but assume instead the more stringent series condition that $\|x_1\| + \|x_2\| + \|x_3\| + \cdots$ converges. Show that $(s_n)$ is a Cauchy sequence, where $s_n = x_1 + \cdots + x_n$.
    \newline\newline
    \textit{Proof:} Suppose $M = \|x_1\| + \|x_2\| + \cdots$ converges. Then $M$ is  a Cauchy sequence, hence, for any $\varepsilon > 0$, there exists an index $N$ such that whenever $n > m > N$, we have 
    \[\sum_{k = m+1}^n \|x_k\| < \varepsilon.\]
    Now, define 
    \[s_n := x_1 + x_2 + \cdots + x_n.\]
    We will show that $(s_n)$ is Cauchy. Let $n > m > N$ as above, and notice
    \begin{align*}
        \|s_n - s_m\|^2 &= \left\langle \sum_{j = m + 1}^{n} x_j, \sum_{k = m + 1}^{n} x_k  \right\rangle\\
        &= \sum_{j = m + 1}^{n} \sum_{k = m + 1}^n \langle x_j, x_k \rangle
    \end{align*}
    and by the Schwarz inequality, we have
    \begin{align*}
        \|s_n - s_m\|^2 &= \left|\sum_{j=m+1}^n\sum_{k=m+1}^n \langle x_j, x_k\rangle\right|\\
        &\leq \sum_{j = m+1}^n\sum_{k = m+1}^n \|x_j\|\|x_k\|\\
        &= \left(\sum_{j = m + 1}^n \|x_j\|\right)\left(\sum_{k = m + 1}^n \|x_k\|\right)\\
        &< \varepsilon \cdot \varepsilon\\
        &= \varepsilon^2.
    \end{align*}
    So now we have $\|s_n - s_m\|^2 < \varepsilon^2$ for all $n>m>N$, hence
    \[\|s_n - s_m\| < \varepsilon\]
    so that $(s_n)$ is a Cauchy sequence. \hfill $\mathghost$
    
\end{itemize}

\end{document}
